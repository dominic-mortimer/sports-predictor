{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling Part 2\n",
    "\n",
    "The purpose of this script is to use the 2018-19 season games and the LUTs we generated to train an ML model to predict the winner of NBA regular season games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>season</th>\n",
       "      <th>home</th>\n",
       "      <th>away</th>\n",
       "      <th>is_home_win</th>\n",
       "      <th>winner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-10-05</td>\n",
       "      <td>2003</td>\n",
       "      <td>UTA</td>\n",
       "      <td>DAL</td>\n",
       "      <td>1</td>\n",
       "      <td>UTA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-10-06</td>\n",
       "      <td>2003</td>\n",
       "      <td>MEM</td>\n",
       "      <td>MIL</td>\n",
       "      <td>1</td>\n",
       "      <td>MEM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-10-07</td>\n",
       "      <td>2003</td>\n",
       "      <td>SAC</td>\n",
       "      <td>LAC</td>\n",
       "      <td>1</td>\n",
       "      <td>SAC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-10-07</td>\n",
       "      <td>2003</td>\n",
       "      <td>POR</td>\n",
       "      <td>HOU</td>\n",
       "      <td>1</td>\n",
       "      <td>POR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-10-07</td>\n",
       "      <td>2003</td>\n",
       "      <td>MIA</td>\n",
       "      <td>PHI</td>\n",
       "      <td>1</td>\n",
       "      <td>MIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  season home away  is_home_win winner\n",
       "0  2003-10-05    2003  UTA  DAL            1    UTA\n",
       "1  2003-10-06    2003  MEM  MIL            1    MEM\n",
       "2  2003-10-07    2003  SAC  LAC            1    SAC\n",
       "3  2003-10-07    2003  POR  HOU            1    POR\n",
       "4  2003-10-07    2003  MIA  PHI            1    MIA"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teams = pd.read_csv('Data/teams.csv')\n",
    "df = pd.read_csv('Data/games_modelling.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "luts = joblib.load('Data/luts.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24677, 6)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24677 entries, 0 to 24676\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   date         24677 non-null  object\n",
      " 1   season       24677 non-null  int64 \n",
      " 2   home         24677 non-null  object\n",
      " 3   away         24677 non-null  object\n",
      " 4   is_home_win  24677 non-null  int64 \n",
      " 5   winner       24677 non-null  object\n",
      "dtypes: int64(2), object(4)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that whenever we load this dataframe, the date column reverts back to an object.  Not sure why, but we can just manually fix this.  We'll also generate our team name - id dictionary as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-format the date column\n",
    "df['date'] = df['date'].astype('datetime64')\n",
    "\n",
    "# generate a team name-ID dictionary from the teams dataset\n",
    "teams = teams[['TEAM_ID', 'ABBREVIATION']]\n",
    "teams = teams.set_index('TEAM_ID')\n",
    "id_to_name = teams.to_dict()['ABBREVIATION']\n",
    "\n",
    "# generate this same dictionary in reverse (i.e. ID-name instead of name-ID)\n",
    "name_to_id = dict((v,k) for k,v in id_to_name.items())  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're in position to get each team's stats going into each game!  Let's start by loading the start and end dates for the regular season games."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_dates = {'2003' : '2003-10-28',\n",
    "              '2004' : '2004-11-02',\n",
    "              '2005' : '2005-11-01',\n",
    "              '2006' : '2006-10-31',\n",
    "              '2007' : '2007-10-30',\n",
    "              '2008' : '2008-10-28',\n",
    "              '2009' : '2009-10-27',\n",
    "              '2010' : '2010-10-26',\n",
    "              '2011' : '2010-12-25',\n",
    "              '2012' : '2012-10-30',\n",
    "              '2013' : '2013-10-29',\n",
    "              '2014' : '2014-10-28',\n",
    "              '2015' : '2015-10-27',\n",
    "              '2016' : '2016-10-25',\n",
    "              '2017' : '2017-10-17',\n",
    "              '2018' : '2018-10-16'}\n",
    "\n",
    "end_dates = {'2003' : '2004-04-14',\n",
    "            '2004' : '2005-04-20',\n",
    "            '2005' : '2006-04-19',\n",
    "            '2006' : '2007-04-18',\n",
    "            '2007' : '2008-04-16',\n",
    "            '2008' : '2009-04-16',\n",
    "            '2009' : '2010-04-14',\n",
    "            '2010' : '2011-04-13',\n",
    "            '2011' : '2012-04-26',\n",
    "            '2012' : '2013-04-17',\n",
    "            '2013' : '2014-04-16',\n",
    "            '2014' : '2015-04-15',\n",
    "            '2015' : '2016-04-13',\n",
    "            '2016' : '2017-04-12',\n",
    "            '2017' : '2018-04-11',\n",
    "            '2018' : '2019-04-10'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can loop through the seasons in the dataframe, and the stats we're tracking for each season.  For each iteration, the approach will be as follows:\n",
    "1. Loop through each season.\n",
    "2. Create new dataframe for the regular season games in this season (these will be saved in a dictionary of dataframes).\n",
    "3. Loop through the stats we want to track.\n",
    "4. Merge the season dataframe with the lut for the stat we're looking at (merge on date), and save this as a temporary df.  This means that for each game, we have all the teams updated stats at the date of the game.\n",
    "5. Loop through all the games in this season.  For each game, update the home and away teams' stats based on their values in the LUT (which has been merged at this point, so is in the same dataframe).\n",
    "6. Once we've looped through all the games, we should have two pandas Series, which correspond to the home and away teams' stats.  All we need to do now is append these Series to the original dataframe for this season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating avg_pts_for for 2003 season\n",
      "Generating avg_pts_against for 2003 season\n",
      "Generating avg_reb_for for 2003 season\n",
      "Generating avg_reb_against for 2003 season\n",
      "Generating avg_ast_for for 2003 season\n",
      "Generating avg_ast_against for 2003 season\n",
      "Generating win_pct for 2003 season\n",
      "Generating avg_pts_for for 2004 season\n",
      "Generating avg_pts_against for 2004 season\n",
      "Generating avg_reb_for for 2004 season\n",
      "Generating avg_reb_against for 2004 season\n",
      "Generating avg_ast_for for 2004 season\n",
      "Generating avg_ast_against for 2004 season\n",
      "Generating win_pct for 2004 season\n",
      "Generating avg_pts_for for 2005 season\n",
      "Generating avg_pts_against for 2005 season\n",
      "Generating avg_reb_for for 2005 season\n",
      "Generating avg_reb_against for 2005 season\n",
      "Generating avg_ast_for for 2005 season\n",
      "Generating avg_ast_against for 2005 season\n",
      "Generating win_pct for 2005 season\n",
      "Generating avg_pts_for for 2006 season\n",
      "Generating avg_pts_against for 2006 season\n",
      "Generating avg_reb_for for 2006 season\n",
      "Generating avg_reb_against for 2006 season\n",
      "Generating avg_ast_for for 2006 season\n",
      "Generating avg_ast_against for 2006 season\n",
      "Generating win_pct for 2006 season\n",
      "Generating avg_pts_for for 2007 season\n",
      "Generating avg_pts_against for 2007 season\n",
      "Generating avg_reb_for for 2007 season\n",
      "Generating avg_reb_against for 2007 season\n",
      "Generating avg_ast_for for 2007 season\n",
      "Generating avg_ast_against for 2007 season\n",
      "Generating win_pct for 2007 season\n",
      "Generating avg_pts_for for 2008 season\n",
      "Generating avg_pts_against for 2008 season\n",
      "Generating avg_reb_for for 2008 season\n",
      "Generating avg_reb_against for 2008 season\n",
      "Generating avg_ast_for for 2008 season\n",
      "Generating avg_ast_against for 2008 season\n",
      "Generating win_pct for 2008 season\n",
      "Generating avg_pts_for for 2009 season\n",
      "Generating avg_pts_against for 2009 season\n",
      "Generating avg_reb_for for 2009 season\n",
      "Generating avg_reb_against for 2009 season\n",
      "Generating avg_ast_for for 2009 season\n",
      "Generating avg_ast_against for 2009 season\n",
      "Generating win_pct for 2009 season\n",
      "Generating avg_pts_for for 2010 season\n",
      "Generating avg_pts_against for 2010 season\n",
      "Generating avg_reb_for for 2010 season\n",
      "Generating avg_reb_against for 2010 season\n",
      "Generating avg_ast_for for 2010 season\n",
      "Generating avg_ast_against for 2010 season\n",
      "Generating win_pct for 2010 season\n",
      "Generating avg_pts_for for 2011 season\n",
      "Generating avg_pts_against for 2011 season\n",
      "Generating avg_reb_for for 2011 season\n",
      "Generating avg_reb_against for 2011 season\n",
      "Generating avg_ast_for for 2011 season\n",
      "Generating avg_ast_against for 2011 season\n",
      "Generating win_pct for 2011 season\n",
      "Generating avg_pts_for for 2012 season\n",
      "Generating avg_pts_against for 2012 season\n",
      "Generating avg_reb_for for 2012 season\n",
      "Generating avg_reb_against for 2012 season\n",
      "Generating avg_ast_for for 2012 season\n",
      "Generating avg_ast_against for 2012 season\n",
      "Generating win_pct for 2012 season\n",
      "Generating avg_pts_for for 2013 season\n",
      "Generating avg_pts_against for 2013 season\n",
      "Generating avg_reb_for for 2013 season\n",
      "Generating avg_reb_against for 2013 season\n",
      "Generating avg_ast_for for 2013 season\n",
      "Generating avg_ast_against for 2013 season\n",
      "Generating win_pct for 2013 season\n",
      "Generating avg_pts_for for 2014 season\n",
      "Generating avg_pts_against for 2014 season\n",
      "Generating avg_reb_for for 2014 season\n",
      "Generating avg_reb_against for 2014 season\n",
      "Generating avg_ast_for for 2014 season\n",
      "Generating avg_ast_against for 2014 season\n",
      "Generating win_pct for 2014 season\n",
      "Generating avg_pts_for for 2015 season\n",
      "Generating avg_pts_against for 2015 season\n",
      "Generating avg_reb_for for 2015 season\n",
      "Generating avg_reb_against for 2015 season\n",
      "Generating avg_ast_for for 2015 season\n",
      "Generating avg_ast_against for 2015 season\n",
      "Generating win_pct for 2015 season\n",
      "Generating avg_pts_for for 2016 season\n",
      "Generating avg_pts_against for 2016 season\n",
      "Generating avg_reb_for for 2016 season\n",
      "Generating avg_reb_against for 2016 season\n",
      "Generating avg_ast_for for 2016 season\n",
      "Generating avg_ast_against for 2016 season\n",
      "Generating win_pct for 2016 season\n",
      "Generating avg_pts_for for 2017 season\n",
      "Generating avg_pts_against for 2017 season\n",
      "Generating avg_reb_for for 2017 season\n",
      "Generating avg_reb_against for 2017 season\n",
      "Generating avg_ast_for for 2017 season\n",
      "Generating avg_ast_against for 2017 season\n",
      "Generating win_pct for 2017 season\n",
      "Generating avg_pts_for for 2018 season\n",
      "Generating avg_pts_against for 2018 season\n",
      "Generating avg_reb_for for 2018 season\n",
      "Generating avg_reb_against for 2018 season\n",
      "Generating avg_ast_for for 2018 season\n",
      "Generating avg_ast_against for 2018 season\n",
      "Generating win_pct for 2018 season\n"
     ]
    }
   ],
   "source": [
    "# initialize the seasons to loop through\n",
    "seasons = np.arange(2003, 2019, 1)\n",
    "\n",
    "# set up the stats to loop through\n",
    "stats = stats = ['avg_pts_for', 'avg_pts_against', 'avg_reb_for', 'avg_reb_against', \n",
    "         'avg_ast_for', 'avg_ast_against', 'win_pct']\n",
    "\n",
    "# initialize our empty dictionary of dataframes\n",
    "games_by_season = {}\n",
    "\n",
    "# loop through the seasons\n",
    "for season in seasons:\n",
    "    \n",
    "    # create the dataframe of games for this regular season\n",
    "    games_by_season[season] = df.loc[df['season'] == season, :]\n",
    "    games_by_season[season] = games_by_season[season].loc[(games_by_season[season]['date'] >= start_dates[str(season)]) & \\\n",
    "                 (games_by_season[season]['date'] <= end_dates[str(season)]), :]\n",
    "    games_by_season[season] = games_by_season[season].reset_index().drop('index', axis=1)\n",
    "        \n",
    "    # loop through the stats\n",
    "    for stat in stats:\n",
    "\n",
    "        print(f'Generating {stat} for {season} season')\n",
    "        \n",
    "        # this is the key for the LUT for this stat\n",
    "        id_ = str(season) + '_' + stat\n",
    "        \n",
    "        # merge the games df with the LUT for this stat, save in temporary df\n",
    "        tmp = pd.merge(games_by_season[season], luts[id_], how='left', on='date')\n",
    "        tmp = tmp.reset_index().drop('index', axis=1)\n",
    "\n",
    "        # initialize our averages for this stat (just to zeros to start)\n",
    "        tmp[f'home_{stat}'] = 0.0\n",
    "        tmp[f'away_{stat}'] = 0.0\n",
    "                \n",
    "        # loop through the home teams, and update their stats at the given date\n",
    "        for i, team in enumerate(tmp['home']):\n",
    "            tmp.loc[i, f'home_{stat}'] = tmp.loc[i, team]\n",
    "\n",
    "        # loop through the away teams, and update their stats at the given date\n",
    "        for i, team in enumerate(tmp['away']):\n",
    "            tmp.loc[i, f'away_{stat}'] = tmp.loc[i, team]\n",
    "        \n",
    "        # take our newly formed statistic columns and add them to the original games df\n",
    "        games_by_season[season][f'home_{stat}'] = tmp[f'home_{stat}']\n",
    "        games_by_season[season][f'away_{stat}'] = tmp[f'away_{stat}']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have a dictionary of dataframes, each of which corresponds to the games in a season.  In order to perform modelling, we should merge these back together.  Something to note, is our models will be trained to predict game outcomes based on each teams' cumulative stats going into the game.  It doesn't really make sense to use these stats early on in the season though.  For example, if we're going to use a team's average points per game as a feature, our average should be based on a decent number of games.  We will therefore set a cutoff date for each season, for which we will only take games which happened after.  This cutoff date will be one month after the start of the season."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# loop through the different dataframes\n",
    "for season in games_by_season:\n",
    "    \n",
    "    # setup a column which represents the cutoff date for this season\n",
    "    games_by_season[season]['cutoff'] = start_dates[str(season)]\n",
    "    games_by_season[season]['cutoff'] = games_by_season[season]['cutoff'].astype('datetime64')\n",
    "    games_by_season[season]['cutoff'] = games_by_season[season]['cutoff'] + pd.DateOffset(months=1)\n",
    "    \n",
    "    # filter for the games which occurred after this cutoff date\n",
    "    games_by_season[season] = games_by_season[season].loc[games_by_season[season]['date'] >= \\\n",
    "                                                         games_by_season[season]['cutoff'], :]\n",
    "    games_by_season[season] = games_by_season[season].reset_index().drop('index', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to re-merge our dataframes for modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to initialize the first df\n",
    "new_df = games_by_season[2003]\n",
    "\n",
    "for season in games_by_season:\n",
    "    \n",
    "    # this df has already been loaded in the initialization step (see above)\n",
    "    if season == 2003:\n",
    "        continue\n",
    "        \n",
    "    # merge the df for this season with the fully merged version\n",
    "    new_df = pd.concat([new_df, games_by_season[season]])\n",
    "    new_df = new_df.reset_index().drop('index', axis=1)\n",
    "    \n",
    "# drop the cutoff column -- we no longer have need of it\n",
    "new_df.drop('cutoff', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at what we have!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>season</th>\n",
       "      <th>home</th>\n",
       "      <th>away</th>\n",
       "      <th>is_home_win</th>\n",
       "      <th>winner</th>\n",
       "      <th>home_avg_pts_for</th>\n",
       "      <th>away_avg_pts_for</th>\n",
       "      <th>home_avg_pts_against</th>\n",
       "      <th>away_avg_pts_against</th>\n",
       "      <th>home_avg_reb_for</th>\n",
       "      <th>away_avg_reb_for</th>\n",
       "      <th>home_avg_reb_against</th>\n",
       "      <th>away_avg_reb_against</th>\n",
       "      <th>home_avg_ast_for</th>\n",
       "      <th>away_avg_ast_for</th>\n",
       "      <th>home_avg_ast_against</th>\n",
       "      <th>away_avg_ast_against</th>\n",
       "      <th>home_win_pct</th>\n",
       "      <th>away_win_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003-11-28</td>\n",
       "      <td>2003</td>\n",
       "      <td>LAL</td>\n",
       "      <td>SAS</td>\n",
       "      <td>1</td>\n",
       "      <td>LAL</td>\n",
       "      <td>103.4</td>\n",
       "      <td>91.2</td>\n",
       "      <td>94.9</td>\n",
       "      <td>84.5</td>\n",
       "      <td>43.1</td>\n",
       "      <td>46.8</td>\n",
       "      <td>42.7</td>\n",
       "      <td>45.0</td>\n",
       "      <td>24.7</td>\n",
       "      <td>21.5</td>\n",
       "      <td>24.7</td>\n",
       "      <td>20.6</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003-11-28</td>\n",
       "      <td>2003</td>\n",
       "      <td>PHX</td>\n",
       "      <td>GSW</td>\n",
       "      <td>0</td>\n",
       "      <td>GSW</td>\n",
       "      <td>93.8</td>\n",
       "      <td>91.2</td>\n",
       "      <td>93.2</td>\n",
       "      <td>89.9</td>\n",
       "      <td>42.2</td>\n",
       "      <td>44.2</td>\n",
       "      <td>42.6</td>\n",
       "      <td>45.2</td>\n",
       "      <td>20.1</td>\n",
       "      <td>21.2</td>\n",
       "      <td>20.9</td>\n",
       "      <td>22.3</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003-11-28</td>\n",
       "      <td>2003</td>\n",
       "      <td>IND</td>\n",
       "      <td>PHI</td>\n",
       "      <td>1</td>\n",
       "      <td>IND</td>\n",
       "      <td>88.3</td>\n",
       "      <td>90.2</td>\n",
       "      <td>80.7</td>\n",
       "      <td>90.2</td>\n",
       "      <td>42.2</td>\n",
       "      <td>39.1</td>\n",
       "      <td>41.6</td>\n",
       "      <td>40.6</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.1</td>\n",
       "      <td>20.5</td>\n",
       "      <td>21.8</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003-11-28</td>\n",
       "      <td>2003</td>\n",
       "      <td>ATL</td>\n",
       "      <td>MIA</td>\n",
       "      <td>1</td>\n",
       "      <td>ATL</td>\n",
       "      <td>90.6</td>\n",
       "      <td>86.2</td>\n",
       "      <td>96.2</td>\n",
       "      <td>93.6</td>\n",
       "      <td>43.6</td>\n",
       "      <td>42.4</td>\n",
       "      <td>45.2</td>\n",
       "      <td>40.9</td>\n",
       "      <td>19.4</td>\n",
       "      <td>16.8</td>\n",
       "      <td>20.8</td>\n",
       "      <td>19.9</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003-11-28</td>\n",
       "      <td>2003</td>\n",
       "      <td>DET</td>\n",
       "      <td>CLE</td>\n",
       "      <td>1</td>\n",
       "      <td>DET</td>\n",
       "      <td>93.7</td>\n",
       "      <td>89.3</td>\n",
       "      <td>89.2</td>\n",
       "      <td>93.7</td>\n",
       "      <td>43.6</td>\n",
       "      <td>47.3</td>\n",
       "      <td>43.0</td>\n",
       "      <td>45.5</td>\n",
       "      <td>19.4</td>\n",
       "      <td>22.3</td>\n",
       "      <td>20.4</td>\n",
       "      <td>22.3</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  season home away  is_home_win winner  home_avg_pts_for  \\\n",
       "0 2003-11-28    2003  LAL  SAS            1    LAL             103.4   \n",
       "1 2003-11-28    2003  PHX  GSW            0    GSW              93.8   \n",
       "2 2003-11-28    2003  IND  PHI            1    IND              88.3   \n",
       "3 2003-11-28    2003  ATL  MIA            1    ATL              90.6   \n",
       "4 2003-11-28    2003  DET  CLE            1    DET              93.7   \n",
       "\n",
       "   away_avg_pts_for  home_avg_pts_against  away_avg_pts_against  \\\n",
       "0              91.2                  94.9                  84.5   \n",
       "1              91.2                  93.2                  89.9   \n",
       "2              90.2                  80.7                  90.2   \n",
       "3              86.2                  96.2                  93.6   \n",
       "4              89.3                  89.2                  93.7   \n",
       "\n",
       "   home_avg_reb_for  away_avg_reb_for  home_avg_reb_against  \\\n",
       "0              43.1              46.8                  42.7   \n",
       "1              42.2              44.2                  42.6   \n",
       "2              42.2              39.1                  41.6   \n",
       "3              43.6              42.4                  45.2   \n",
       "4              43.6              47.3                  43.0   \n",
       "\n",
       "   away_avg_reb_against  home_avg_ast_for  away_avg_ast_for  \\\n",
       "0                  45.0              24.7              21.5   \n",
       "1                  45.2              20.1              21.2   \n",
       "2                  40.6              20.6              20.1   \n",
       "3                  40.9              19.4              16.8   \n",
       "4                  45.5              19.4              22.3   \n",
       "\n",
       "   home_avg_ast_against  away_avg_ast_against  home_win_pct  away_win_pct  \n",
       "0                  24.7                  20.6         0.800         0.600  \n",
       "1                  20.9                  22.3         0.500         0.462  \n",
       "2                  20.5                  21.8         0.867         0.500  \n",
       "3                  20.8                  19.9         0.312         0.267  \n",
       "4                  20.4                  22.3         0.625         0.267  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16121, 20)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's looking pretty good!  For modelling though, we don't really care about some of these columns, so let's fix that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>home_avg_pts_for</th>\n",
       "      <th>away_avg_pts_for</th>\n",
       "      <th>home_avg_pts_against</th>\n",
       "      <th>away_avg_pts_against</th>\n",
       "      <th>home_avg_reb_for</th>\n",
       "      <th>away_avg_reb_for</th>\n",
       "      <th>home_avg_reb_against</th>\n",
       "      <th>away_avg_reb_against</th>\n",
       "      <th>home_avg_ast_for</th>\n",
       "      <th>away_avg_ast_for</th>\n",
       "      <th>home_avg_ast_against</th>\n",
       "      <th>away_avg_ast_against</th>\n",
       "      <th>home_win_pct</th>\n",
       "      <th>away_win_pct</th>\n",
       "      <th>is_home_win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>103.4</td>\n",
       "      <td>91.2</td>\n",
       "      <td>94.9</td>\n",
       "      <td>84.5</td>\n",
       "      <td>43.1</td>\n",
       "      <td>46.8</td>\n",
       "      <td>42.7</td>\n",
       "      <td>45.0</td>\n",
       "      <td>24.7</td>\n",
       "      <td>21.5</td>\n",
       "      <td>24.7</td>\n",
       "      <td>20.6</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>93.8</td>\n",
       "      <td>91.2</td>\n",
       "      <td>93.2</td>\n",
       "      <td>89.9</td>\n",
       "      <td>42.2</td>\n",
       "      <td>44.2</td>\n",
       "      <td>42.6</td>\n",
       "      <td>45.2</td>\n",
       "      <td>20.1</td>\n",
       "      <td>21.2</td>\n",
       "      <td>20.9</td>\n",
       "      <td>22.3</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.462</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>88.3</td>\n",
       "      <td>90.2</td>\n",
       "      <td>80.7</td>\n",
       "      <td>90.2</td>\n",
       "      <td>42.2</td>\n",
       "      <td>39.1</td>\n",
       "      <td>41.6</td>\n",
       "      <td>40.6</td>\n",
       "      <td>20.6</td>\n",
       "      <td>20.1</td>\n",
       "      <td>20.5</td>\n",
       "      <td>21.8</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>90.6</td>\n",
       "      <td>86.2</td>\n",
       "      <td>96.2</td>\n",
       "      <td>93.6</td>\n",
       "      <td>43.6</td>\n",
       "      <td>42.4</td>\n",
       "      <td>45.2</td>\n",
       "      <td>40.9</td>\n",
       "      <td>19.4</td>\n",
       "      <td>16.8</td>\n",
       "      <td>20.8</td>\n",
       "      <td>19.9</td>\n",
       "      <td>0.312</td>\n",
       "      <td>0.267</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93.7</td>\n",
       "      <td>89.3</td>\n",
       "      <td>89.2</td>\n",
       "      <td>93.7</td>\n",
       "      <td>43.6</td>\n",
       "      <td>47.3</td>\n",
       "      <td>43.0</td>\n",
       "      <td>45.5</td>\n",
       "      <td>19.4</td>\n",
       "      <td>22.3</td>\n",
       "      <td>20.4</td>\n",
       "      <td>22.3</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.267</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   home_avg_pts_for  away_avg_pts_for  home_avg_pts_against  \\\n",
       "0             103.4              91.2                  94.9   \n",
       "1              93.8              91.2                  93.2   \n",
       "2              88.3              90.2                  80.7   \n",
       "3              90.6              86.2                  96.2   \n",
       "4              93.7              89.3                  89.2   \n",
       "\n",
       "   away_avg_pts_against  home_avg_reb_for  away_avg_reb_for  \\\n",
       "0                  84.5              43.1              46.8   \n",
       "1                  89.9              42.2              44.2   \n",
       "2                  90.2              42.2              39.1   \n",
       "3                  93.6              43.6              42.4   \n",
       "4                  93.7              43.6              47.3   \n",
       "\n",
       "   home_avg_reb_against  away_avg_reb_against  home_avg_ast_for  \\\n",
       "0                  42.7                  45.0              24.7   \n",
       "1                  42.6                  45.2              20.1   \n",
       "2                  41.6                  40.6              20.6   \n",
       "3                  45.2                  40.9              19.4   \n",
       "4                  43.0                  45.5              19.4   \n",
       "\n",
       "   away_avg_ast_for  home_avg_ast_against  away_avg_ast_against  home_win_pct  \\\n",
       "0              21.5                  24.7                  20.6         0.800   \n",
       "1              21.2                  20.9                  22.3         0.500   \n",
       "2              20.1                  20.5                  21.8         0.867   \n",
       "3              16.8                  20.8                  19.9         0.312   \n",
       "4              22.3                  20.4                  22.3         0.625   \n",
       "\n",
       "   away_win_pct  is_home_win  \n",
       "0         0.600            1  \n",
       "1         0.462            0  \n",
       "2         0.500            1  \n",
       "3         0.267            1  \n",
       "4         0.267            1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = new_df.columns.tolist()\n",
    "cols = cols[6:] + [cols[4]]\n",
    "\n",
    "new_df = new_df[cols]\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now we have what looks to be a pretty good dataset for modelling.  Let's save it, and load it back in in another script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv('Data/games_modelling2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
