{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LUT Generator\n",
    "\n",
    "The purpose of this notebook is to generate a set of look-up tables, for all the NBA teams' stats at every point in the 2018-19 season.  These stats are\n",
    "- average points for per game\n",
    "- average points against per game\n",
    "- average rebounds for per game\n",
    "- average rebounds against per game\n",
    "- average assists for per game\n",
    "- average assists against per game\n",
    "- winning percentage\n",
    "\n",
    "They are then saved into a `pkl` file called `luts.pkl`, which can then be loaded into memory in future notebooks.  We start here by importing some libraries, and reading in the data for this season.  Note that the season data is generated in the `EDA.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GAME_DATE_EST</th>\n",
       "      <th>GAME_ID</th>\n",
       "      <th>GAME_STATUS_TEXT</th>\n",
       "      <th>HOME_TEAM_ID</th>\n",
       "      <th>VISITOR_TEAM_ID</th>\n",
       "      <th>SEASON</th>\n",
       "      <th>TEAM_ID_home</th>\n",
       "      <th>PTS_home</th>\n",
       "      <th>FG_PCT_home</th>\n",
       "      <th>FT_PCT_home</th>\n",
       "      <th>...</th>\n",
       "      <th>AST_home</th>\n",
       "      <th>REB_home</th>\n",
       "      <th>TEAM_ID_away</th>\n",
       "      <th>PTS_away</th>\n",
       "      <th>FG_PCT_away</th>\n",
       "      <th>FT_PCT_away</th>\n",
       "      <th>FG3_PCT_away</th>\n",
       "      <th>AST_away</th>\n",
       "      <th>REB_away</th>\n",
       "      <th>HOME_TEAM_WINS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-26</td>\n",
       "      <td>42000102</td>\n",
       "      <td>Final</td>\n",
       "      <td>1610612755</td>\n",
       "      <td>1610612764</td>\n",
       "      <td>2020</td>\n",
       "      <td>1610612755</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.557</td>\n",
       "      <td>0.684</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1610612764</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.402</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.091</td>\n",
       "      <td>22.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-05-26</td>\n",
       "      <td>42000132</td>\n",
       "      <td>Final</td>\n",
       "      <td>1610612752</td>\n",
       "      <td>1610612737</td>\n",
       "      <td>2020</td>\n",
       "      <td>1610612752</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.739</td>\n",
       "      <td>...</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1610612737</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.369</td>\n",
       "      <td>0.818</td>\n",
       "      <td>0.273</td>\n",
       "      <td>17.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-05-26</td>\n",
       "      <td>42000142</td>\n",
       "      <td>Final</td>\n",
       "      <td>1610612762</td>\n",
       "      <td>1610612763</td>\n",
       "      <td>2020</td>\n",
       "      <td>1610612762</td>\n",
       "      <td>141.0</td>\n",
       "      <td>0.544</td>\n",
       "      <td>0.774</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>1610612763</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.541</td>\n",
       "      <td>0.763</td>\n",
       "      <td>0.348</td>\n",
       "      <td>20.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-05-25</td>\n",
       "      <td>42000112</td>\n",
       "      <td>Final</td>\n",
       "      <td>1610612751</td>\n",
       "      <td>1610612738</td>\n",
       "      <td>2020</td>\n",
       "      <td>1610612751</td>\n",
       "      <td>130.0</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.955</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1610612738</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.783</td>\n",
       "      <td>0.353</td>\n",
       "      <td>23.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-25</td>\n",
       "      <td>42000152</td>\n",
       "      <td>Final</td>\n",
       "      <td>1610612756</td>\n",
       "      <td>1610612747</td>\n",
       "      <td>2020</td>\n",
       "      <td>1610612756</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.465</td>\n",
       "      <td>0.933</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1610612747</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.303</td>\n",
       "      <td>24.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  GAME_DATE_EST   GAME_ID GAME_STATUS_TEXT  HOME_TEAM_ID  VISITOR_TEAM_ID  \\\n",
       "0    2021-05-26  42000102            Final    1610612755       1610612764   \n",
       "1    2021-05-26  42000132            Final    1610612752       1610612737   \n",
       "2    2021-05-26  42000142            Final    1610612762       1610612763   \n",
       "3    2021-05-25  42000112            Final    1610612751       1610612738   \n",
       "4    2021-05-25  42000152            Final    1610612756       1610612747   \n",
       "\n",
       "   SEASON  TEAM_ID_home  PTS_home  FG_PCT_home  FT_PCT_home  ...  AST_home  \\\n",
       "0    2020    1610612755     120.0        0.557        0.684  ...      26.0   \n",
       "1    2020    1610612752     101.0        0.383        0.739  ...      15.0   \n",
       "2    2020    1610612762     141.0        0.544        0.774  ...      28.0   \n",
       "3    2020    1610612751     130.0        0.523        0.955  ...      31.0   \n",
       "4    2020    1610612756     102.0        0.465        0.933  ...      21.0   \n",
       "\n",
       "   REB_home  TEAM_ID_away  PTS_away  FG_PCT_away  FT_PCT_away  FG3_PCT_away  \\\n",
       "0      45.0    1610612764      95.0        0.402        0.633         0.091   \n",
       "1      54.0    1610612737      92.0        0.369        0.818         0.273   \n",
       "2      42.0    1610612763     129.0        0.541        0.763         0.348   \n",
       "3      46.0    1610612738     108.0        0.424        0.783         0.353   \n",
       "4      31.0    1610612747     109.0        0.450        0.871         0.303   \n",
       "\n",
       "   AST_away  REB_away  HOME_TEAM_WINS  \n",
       "0      22.0      40.0               1  \n",
       "1      17.0      41.0               1  \n",
       "2      20.0      33.0               1  \n",
       "3      23.0      43.0               1  \n",
       "4      24.0      39.0               0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('Data/games.csv')\n",
    "teams = pd.read_csv('Data/teams.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24677 entries, 0 to 24676\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   GAME_DATE_EST     24677 non-null  object \n",
      " 1   GAME_ID           24677 non-null  int64  \n",
      " 2   GAME_STATUS_TEXT  24677 non-null  object \n",
      " 3   HOME_TEAM_ID      24677 non-null  int64  \n",
      " 4   VISITOR_TEAM_ID   24677 non-null  int64  \n",
      " 5   SEASON            24677 non-null  int64  \n",
      " 6   TEAM_ID_home      24677 non-null  int64  \n",
      " 7   PTS_home          24578 non-null  float64\n",
      " 8   FG_PCT_home       24578 non-null  float64\n",
      " 9   FT_PCT_home       24578 non-null  float64\n",
      " 10  FG3_PCT_home      24578 non-null  float64\n",
      " 11  AST_home          24578 non-null  float64\n",
      " 12  REB_home          24578 non-null  float64\n",
      " 13  TEAM_ID_away      24677 non-null  int64  \n",
      " 14  PTS_away          24578 non-null  float64\n",
      " 15  FG_PCT_away       24578 non-null  float64\n",
      " 16  FT_PCT_away       24578 non-null  float64\n",
      " 17  FG3_PCT_away      24578 non-null  float64\n",
      " 18  AST_away          24578 non-null  float64\n",
      " 19  REB_away          24578 non-null  float64\n",
      " 20  HOME_TEAM_WINS    24677 non-null  int64  \n",
      "dtypes: float64(12), int64(7), object(2)\n",
      "memory usage: 4.0+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like our date column is not in datetime format, and it would be useful to have a dictionary where we can look up a team's name, given their team ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# re-name the date column\n",
    "df = df.rename(columns={'GAME_DATE_EST' : 'date'})\n",
    "\n",
    "# re-format the date column\n",
    "df['date'] = df['date'].astype('datetime64')\n",
    "\n",
    "# sort the df by date\n",
    "df = df.sort_values('date')\n",
    "\n",
    "# generate a team name-ID dictionary from the teams dataset\n",
    "teams = teams[['TEAM_ID', 'ABBREVIATION']]\n",
    "teams = teams.set_index('TEAM_ID')\n",
    "id_to_name = teams.to_dict()['ABBREVIATION']\n",
    "\n",
    "# generate this same dictionary in reverse (i.e. ID-name instead of name-ID)\n",
    "name_to_id = dict((v,k) for k,v in id_to_name.items())    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's define the functions which will calculate our game statistics.  These will be written out fairly long, and I am aware that it could definitely be shortened, but for now I will simply get the LUTs generated, and worry about the quality of the code a little later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_pts_for(df, teams):\n",
    "    '''\n",
    "    This function takes in the games dataframe for a single team, and returns a Series corresponding to the \n",
    "    team's average point total per game, at the time of each game\n",
    "    '''\n",
    "    df['pts_scored'] = np.where(df['is_home'], df['PTS_home'], df['PTS_away'])\n",
    "    df['avg_pts'] = round(df['pts_scored'].expanding().mean(), 1)\n",
    "\n",
    "    return df['avg_pts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_pts_against(df, teams):\n",
    "    '''\n",
    "    This function takes in the games dataframe for a single team, and returns a Series corresponding to the \n",
    "    team's average point total per game, at the time of each game\n",
    "    '''\n",
    "    df['pts_scored'] = np.where(df['is_home'], df['PTS_away'], df['PTS_home'])\n",
    "    df['avg_pts'] = round(df['pts_scored'].expanding().mean(), 1)\n",
    "\n",
    "    return df['avg_pts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_reb_for(df, teams):\n",
    "    '''\n",
    "    This function takes in the games dataframe for a single team, and returns a Series corresponding to the \n",
    "    team's average rebound total per game, at the time of each game\n",
    "    '''\n",
    "    df['rebounds'] = np.where(df['is_home'], df['REB_home'], df['REB_away'])\n",
    "    df['avg_reb'] = round(df['rebounds'].expanding().mean(), 1)\n",
    "\n",
    "    return df['avg_reb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_reb_against(df, teams):\n",
    "    '''\n",
    "    This function takes in the games dataframe for a single team, and returns a Series corresponding to the \n",
    "    team's average rebound total per game, at the time of each game\n",
    "    '''\n",
    "    df['rebounds'] = np.where(~df['is_home'], df['REB_home'], df['REB_away'])\n",
    "    df['avg_reb'] = round(df['rebounds'].expanding().mean(), 1)\n",
    "\n",
    "    return df['avg_reb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_ast_for(df, teams):\n",
    "    '''\n",
    "    This function takes in the games dataframe for a single team, and returns a Series corresponding to the \n",
    "    team's average rebound total per game, at the time of each game\n",
    "    '''\n",
    "    df['assists'] = np.where(df['is_home'], df['AST_home'], df['AST_away'])\n",
    "    df['avg_ast'] = round(df['assists'].expanding().mean(), 1)\n",
    "\n",
    "    return df['avg_ast']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avg_ast_against(df, teams):\n",
    "    '''\n",
    "    This function takes in the games dataframe for a single team, and returns a Series corresponding to the \n",
    "    team's average rebound total per game, at the time of each game\n",
    "    '''\n",
    "    df['assists'] = np.where(~df['is_home'], df['AST_home'], df['AST_away'])\n",
    "    df['avg_ast'] = round(df['assists'].expanding().mean(), 1)\n",
    "\n",
    "    return df['avg_ast']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_win_pct(df, teams):\n",
    "    '''\n",
    "    This function takes in the games dataframe for a single team, and returns a Series corresponding to the\n",
    "    team's winning percentage at the time of each game\n",
    "    '''\n",
    "    df['is_win'] = np.where(df['HOME_TEAM_WINS'] == df['is_home'], 1, 0)\n",
    "    df['num_wins'] = df['is_win'].cumsum()\n",
    "    df['num_games'] = df.index + 1\n",
    "    df['win_pct'] = round(df['num_wins'] / df['num_games'], 3)\n",
    "    \n",
    "    return df['win_pct']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we have pre-season and playoff games in our dataset, let's take into account the start and end dates of each regular season.  This way, our cumulative season stats will make more sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_dates = {'2003' : '2003-10-28',\n",
    "              '2004' : '2004-11-02',\n",
    "              '2005' : '2005-11-01',\n",
    "              '2006' : '2006-10-31',\n",
    "              '2007' : '2007-10-30',\n",
    "              '2008' : '2008-10-28',\n",
    "              '2009' : '2009-10-27',\n",
    "              '2010' : '2010-10-26',\n",
    "              '2011' : '2010-12-25',\n",
    "              '2012' : '2012-10-30',\n",
    "              '2013' : '2013-10-29',\n",
    "              '2014' : '2014-10-28',\n",
    "              '2015' : '2015-10-27',\n",
    "              '2016' : '2016-10-25',\n",
    "              '2017' : '2017-10-17',\n",
    "              '2018' : '2018-10-16'}\n",
    "\n",
    "end_dates = {'2003' : '2004-04-14',\n",
    "            '2004' : '2005-04-20',\n",
    "            '2005' : '2006-04-19',\n",
    "            '2006' : '2007-04-18',\n",
    "            '2007' : '2008-04-16',\n",
    "            '2008' : '2009-04-16',\n",
    "            '2009' : '2010-04-14',\n",
    "            '2010' : '2011-04-13',\n",
    "            '2011' : '2012-04-26',\n",
    "            '2012' : '2013-04-17',\n",
    "            '2013' : '2014-04-16',\n",
    "            '2014' : '2015-04-15',\n",
    "            '2015' : '2016-04-13',\n",
    "            '2016' : '2017-04-12',\n",
    "            '2017' : '2018-04-11',\n",
    "            '2018' : '2019-04-10'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to generate tables for each team, each row of which will correspond to a game in which that team played.  The columns will represent the cumulative stats of that team, after that game has been played (e.g. updated winning percentage).  We can then use those tables to generate LUTs for each individual statistic.\n",
    "\n",
    "Note that the tables for each team will be stored in a single dictionary, `data_dict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating game-by-game statistics for GSW in 2018 season\r"
     ]
    }
   ],
   "source": [
    "# initialize the dictionary of dataframes\n",
    "data_dict = {}\n",
    "\n",
    "# initialize the seasons to loop through\n",
    "seasons = np.arange(2003, 2019, 1)\n",
    "\n",
    "# cycle through the different seasons\n",
    "for season in seasons:\n",
    "\n",
    "    # filter original dataframe for games which occurred during this season\n",
    "    tmp = df.loc[df['SEASON'] == season, :]\n",
    "    \n",
    "    # filter for regular season games only\n",
    "    tmp = tmp.loc[(tmp['date'] >= start_dates[str(season)]) & \\\n",
    "                 (tmp['date'] <= end_dates[str(season)]), :]\n",
    "    \n",
    "    # cycle through the different teams \n",
    "    for team_id in id_to_name:\n",
    "\n",
    "        print(f'Generating game-by-game statistics for {id_to_name[team_id]} in {season} season', end='\\r')\n",
    "\n",
    "        # this will be the unique key which will identify this teams df for this season\n",
    "        id_ = str(season) + '_' + id_to_name[team_id]\n",
    "        \n",
    "        # select out games from this season which this team played in\n",
    "        data_dict[id_] = tmp.loc[(df['HOME_TEAM_ID'] == team_id) | \\\n",
    "                                    (df['VISITOR_TEAM_ID'] == team_id), :].reset_index().drop('index', axis=1)\n",
    "        \n",
    "        # not all the teams are in the league for all the seasons, so if it's an empty df, just continue\n",
    "        if (data_dict[id_].shape[0] == 0):\n",
    "            continue\n",
    "\n",
    "        # knowing whether this is a home game or not will make the calculations easier later\n",
    "        data_dict[id_]['team_name'] = id_to_name[team_id]\n",
    "        data_dict[id_]['home_name'] = data_dict[id_]['HOME_TEAM_ID'].map(id_to_name)\n",
    "        data_dict[id_]['is_home'] = np.where(data_dict[id_]['team_name'] == data_dict[id_]['home_name'], 1, 0)\n",
    "\n",
    "        # get average point numbers\n",
    "        data_dict[id_]['avg_pts_against'] = get_avg_pts_against(data_dict[id_], id_to_name)\n",
    "        data_dict[id_]['avg_pts_for']     = get_avg_pts_for(data_dict[id_], id_to_name)\n",
    "\n",
    "        # get average rebound numbers\n",
    "        data_dict[id_]['avg_reb_for']     = get_avg_reb_for(data_dict[id_], id_to_name)\n",
    "        data_dict[id_]['avg_reb_against'] = get_avg_reb_against(data_dict[id_], id_to_name)\n",
    "\n",
    "        # get average assist numbers\n",
    "        data_dict[id_]['avg_ast_for']     = get_avg_ast_for(data_dict[id_], id_to_name)\n",
    "        data_dict[id_]['avg_ast_against']     = get_avg_ast_against(data_dict[id_], id_to_name)\n",
    "\n",
    "        # get winning percentage\n",
    "        data_dict[id_]['win_pct']         = get_win_pct(data_dict[id_], id_to_name)\n",
    "\n",
    "        # reduce the number of columns to only the date and stats we want\n",
    "        data_dict[id_] = data_dict[id_].loc[:, ['date', 'avg_pts_for', 'avg_pts_against', \n",
    "                                                        'avg_reb_for', 'avg_reb_against', 'avg_ast_for',\n",
    "                                                        'avg_ast_against', 'win_pct']]\n",
    "\n",
    "        last_ix = data_dict[id_].shape[0] - 1\n",
    "        last_date = data_dict[id_].loc[data_dict[id_].shape[0] - 1, 'date']\n",
    "\n",
    "        # shift the dataframe so that we are looking at the average going into that game\n",
    "        data_dict[id_] = data_dict[id_].shift(1)\n",
    "        data_dict[id_]['new_date'] = data_dict[id_].shift(-1)['date']\n",
    "        data_dict[id_].loc[last_ix, 'new_date'] = data_dict[id_].loc[last_ix, 'date']\n",
    "        data_dict[id_] = data_dict[id_].fillna(0.0)\n",
    "        data_dict[id_].loc[last_ix, 'new_date'] = last_date\n",
    "        data_dict[id_]['date'] = data_dict[id_]['new_date']\n",
    "        data_dict[id_].drop('new_date', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at one of these newly generated dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>avg_pts_for</th>\n",
       "      <th>avg_pts_against</th>\n",
       "      <th>avg_reb_for</th>\n",
       "      <th>avg_reb_against</th>\n",
       "      <th>avg_ast_for</th>\n",
       "      <th>avg_ast_against</th>\n",
       "      <th>win_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-10-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-10-19</td>\n",
       "      <td>116.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-10-20</td>\n",
       "      <td>114.5</td>\n",
       "      <td>102.5</td>\n",
       "      <td>46.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>22.5</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-10-22</td>\n",
       "      <td>115.3</td>\n",
       "      <td>106.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>21.7</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-10-24</td>\n",
       "      <td>118.2</td>\n",
       "      <td>106.0</td>\n",
       "      <td>47.5</td>\n",
       "      <td>43.8</td>\n",
       "      <td>25.5</td>\n",
       "      <td>25.2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        date  avg_pts_for  avg_pts_against  avg_reb_for  avg_reb_against  \\\n",
       "0 2018-10-17          0.0              0.0          0.0              0.0   \n",
       "1 2018-10-19        116.0            104.0         43.0             43.0   \n",
       "2 2018-10-20        114.5            102.5         46.0             46.0   \n",
       "3 2018-10-22        115.3            106.0         48.0             43.0   \n",
       "4 2018-10-24        118.2            106.0         47.5             43.8   \n",
       "\n",
       "   avg_ast_for  avg_ast_against  win_pct  \n",
       "0          0.0              0.0      0.0  \n",
       "1         21.0             21.0      1.0  \n",
       "2         22.5             22.5      1.0  \n",
       "3         22.0             21.7      1.0  \n",
       "4         25.5             25.2      1.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = data_dict['2018_TOR']\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82, 8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we've generated these tables correctly (you can fact-check these numbers with a quick Google search).  Let's now convert this into some LUTs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating LUTs for season 2018\r"
     ]
    }
   ],
   "source": [
    "# set up the different stats we're going to make LUTs for\n",
    "stats = ['avg_pts_for', 'avg_pts_against', 'avg_reb_for', 'avg_reb_against', \n",
    "         'avg_ast_for', 'avg_ast_against', 'win_pct']\n",
    "\n",
    "# initialize the dictionary of LUTs\n",
    "luts = {}\n",
    "\n",
    "for season in seasons:\n",
    "\n",
    "    print(f'Generating LUTs for season {season}', end='\\r')\n",
    "    \n",
    "    # loop through the stats\n",
    "    for stat in stats:\n",
    "\n",
    "        # initialize the LUT for this stat\n",
    "        lut = pd.DataFrame(pd.date_range(start=start_dates[str(season)], \n",
    "                                         end=end_dates[str(season)]), columns=['date'])\n",
    "\n",
    "        # loop through each team in the dictionary of dataframes\n",
    "        for team in name_to_id.keys():\n",
    "\n",
    "            # this is the unique id which is a key in our data_dict dictionary\n",
    "            data_dict_id = str(season) + '_' + team\n",
    "\n",
    "            # some of them are empty, so we need to account for that\n",
    "            if (data_dict[data_dict_id]).empty:\n",
    "                continue\n",
    "            \n",
    "            # merge the date DataFrame with the column for this stat for this team\n",
    "            lut = pd.merge(lut, data_dict[data_dict_id][['date', stat]], how='left', on='date')\n",
    "            lut.rename(columns={stat : team}, inplace=True)\n",
    "            lut.fillna(method='ffill', inplace=True)\n",
    "            lut.fillna(0.0, inplace=True)\n",
    "\n",
    "        # set up the unique key for this stat and this season, and save the newly generated LUT\n",
    "        id_ = str(season) + '_' + stat\n",
    "        luts[id_] = lut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check how these LUTs came out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ATL</th>\n",
       "      <th>BOS</th>\n",
       "      <th>NOP</th>\n",
       "      <th>CHI</th>\n",
       "      <th>DAL</th>\n",
       "      <th>DEN</th>\n",
       "      <th>HOU</th>\n",
       "      <th>LAC</th>\n",
       "      <th>LAL</th>\n",
       "      <th>...</th>\n",
       "      <th>SAS</th>\n",
       "      <th>OKC</th>\n",
       "      <th>TOR</th>\n",
       "      <th>UTA</th>\n",
       "      <th>MEM</th>\n",
       "      <th>WAS</th>\n",
       "      <th>DET</th>\n",
       "      <th>CHA</th>\n",
       "      <th>CLE</th>\n",
       "      <th>GSW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-10-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-10-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-10-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-10-19</td>\n",
       "      <td>107.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-10-20</td>\n",
       "      <td>107.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>119.0</td>\n",
       "      <td>...</td>\n",
       "      <td>112.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>114.5</td>\n",
       "      <td>123.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>108.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date    ATL    BOS    NOP    CHI    DAL    DEN    HOU   LAC    LAL  \\\n",
       "0 2018-10-16    0.0    0.0    0.0    0.0    0.0    0.0    0.0   0.0    0.0   \n",
       "1 2018-10-17    0.0    0.0    0.0    0.0    0.0    0.0    0.0   0.0    0.0   \n",
       "2 2018-10-18    0.0    0.0    0.0    0.0    0.0    0.0    0.0   0.0    0.0   \n",
       "3 2018-10-19  107.0  105.0  131.0    0.0    0.0    0.0    0.0  98.0    0.0   \n",
       "4 2018-10-20  107.0  103.0  131.0  108.0  100.0  107.0  112.0  98.0  119.0   \n",
       "\n",
       "   ...    SAS    OKC    TOR    UTA   MEM    WAS    DET    CHA    CLE    GSW  \n",
       "0  ...    0.0    0.0    0.0    0.0   0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "1  ...    0.0    0.0    0.0    0.0   0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "2  ...    0.0    0.0    0.0    0.0   0.0    0.0    0.0    0.0    0.0    0.0  \n",
       "3  ...    0.0  100.0  116.0  123.0  83.0    0.0    0.0  112.0  104.0  108.0  \n",
       "4  ...  112.0  100.0  114.5  123.0  83.0  112.0  103.0  116.0  104.0  108.0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luts['2018_avg_pts_for'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ATL</th>\n",
       "      <th>BOS</th>\n",
       "      <th>NOP</th>\n",
       "      <th>CHI</th>\n",
       "      <th>DAL</th>\n",
       "      <th>DEN</th>\n",
       "      <th>HOU</th>\n",
       "      <th>LAC</th>\n",
       "      <th>LAL</th>\n",
       "      <th>...</th>\n",
       "      <th>SAS</th>\n",
       "      <th>OKC</th>\n",
       "      <th>TOR</th>\n",
       "      <th>UTA</th>\n",
       "      <th>MEM</th>\n",
       "      <th>WAS</th>\n",
       "      <th>DET</th>\n",
       "      <th>CHA</th>\n",
       "      <th>CLE</th>\n",
       "      <th>GSW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>2019-04-06</td>\n",
       "      <td>113.2</td>\n",
       "      <td>112.3</td>\n",
       "      <td>115.2</td>\n",
       "      <td>105.2</td>\n",
       "      <td>108.6</td>\n",
       "      <td>110.8</td>\n",
       "      <td>113.4</td>\n",
       "      <td>114.9</td>\n",
       "      <td>111.8</td>\n",
       "      <td>...</td>\n",
       "      <td>111.5</td>\n",
       "      <td>114.0</td>\n",
       "      <td>114.4</td>\n",
       "      <td>111.3</td>\n",
       "      <td>102.8</td>\n",
       "      <td>114.2</td>\n",
       "      <td>107.2</td>\n",
       "      <td>110.6</td>\n",
       "      <td>104.6</td>\n",
       "      <td>117.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>2019-04-07</td>\n",
       "      <td>113.2</td>\n",
       "      <td>112.4</td>\n",
       "      <td>115.4</td>\n",
       "      <td>105.2</td>\n",
       "      <td>108.7</td>\n",
       "      <td>110.9</td>\n",
       "      <td>113.5</td>\n",
       "      <td>114.9</td>\n",
       "      <td>111.9</td>\n",
       "      <td>...</td>\n",
       "      <td>111.7</td>\n",
       "      <td>114.1</td>\n",
       "      <td>114.3</td>\n",
       "      <td>111.4</td>\n",
       "      <td>103.0</td>\n",
       "      <td>114.1</td>\n",
       "      <td>107.2</td>\n",
       "      <td>110.6</td>\n",
       "      <td>104.8</td>\n",
       "      <td>117.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>2019-04-08</td>\n",
       "      <td>113.2</td>\n",
       "      <td>112.4</td>\n",
       "      <td>115.4</td>\n",
       "      <td>105.2</td>\n",
       "      <td>108.7</td>\n",
       "      <td>110.9</td>\n",
       "      <td>113.5</td>\n",
       "      <td>114.9</td>\n",
       "      <td>111.9</td>\n",
       "      <td>...</td>\n",
       "      <td>111.7</td>\n",
       "      <td>114.1</td>\n",
       "      <td>114.3</td>\n",
       "      <td>111.4</td>\n",
       "      <td>103.0</td>\n",
       "      <td>114.1</td>\n",
       "      <td>107.2</td>\n",
       "      <td>110.6</td>\n",
       "      <td>104.8</td>\n",
       "      <td>117.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>2019-04-09</td>\n",
       "      <td>113.2</td>\n",
       "      <td>112.3</td>\n",
       "      <td>115.6</td>\n",
       "      <td>105.1</td>\n",
       "      <td>108.9</td>\n",
       "      <td>110.8</td>\n",
       "      <td>114.0</td>\n",
       "      <td>114.9</td>\n",
       "      <td>111.9</td>\n",
       "      <td>...</td>\n",
       "      <td>111.7</td>\n",
       "      <td>114.4</td>\n",
       "      <td>114.4</td>\n",
       "      <td>111.3</td>\n",
       "      <td>103.3</td>\n",
       "      <td>114.1</td>\n",
       "      <td>107.0</td>\n",
       "      <td>110.5</td>\n",
       "      <td>104.6</td>\n",
       "      <td>117.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>2019-04-10</td>\n",
       "      <td>113.1</td>\n",
       "      <td>112.3</td>\n",
       "      <td>115.6</td>\n",
       "      <td>104.9</td>\n",
       "      <td>109.0</td>\n",
       "      <td>110.8</td>\n",
       "      <td>114.0</td>\n",
       "      <td>114.8</td>\n",
       "      <td>111.9</td>\n",
       "      <td>...</td>\n",
       "      <td>111.7</td>\n",
       "      <td>114.3</td>\n",
       "      <td>114.4</td>\n",
       "      <td>111.4</td>\n",
       "      <td>103.2</td>\n",
       "      <td>114.1</td>\n",
       "      <td>107.0</td>\n",
       "      <td>110.7</td>\n",
       "      <td>104.6</td>\n",
       "      <td>117.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date    ATL    BOS    NOP    CHI    DAL    DEN    HOU    LAC    LAL  \\\n",
       "172 2019-04-06  113.2  112.3  115.2  105.2  108.6  110.8  113.4  114.9  111.8   \n",
       "173 2019-04-07  113.2  112.4  115.4  105.2  108.7  110.9  113.5  114.9  111.9   \n",
       "174 2019-04-08  113.2  112.4  115.4  105.2  108.7  110.9  113.5  114.9  111.9   \n",
       "175 2019-04-09  113.2  112.3  115.6  105.1  108.9  110.8  114.0  114.9  111.9   \n",
       "176 2019-04-10  113.1  112.3  115.6  104.9  109.0  110.8  114.0  114.8  111.9   \n",
       "\n",
       "     ...    SAS    OKC    TOR    UTA    MEM    WAS    DET    CHA    CLE    GSW  \n",
       "172  ...  111.5  114.0  114.4  111.3  102.8  114.2  107.2  110.6  104.6  117.6  \n",
       "173  ...  111.7  114.1  114.3  111.4  103.0  114.1  107.2  110.6  104.8  117.6  \n",
       "174  ...  111.7  114.1  114.3  111.4  103.0  114.1  107.2  110.6  104.8  117.6  \n",
       "175  ...  111.7  114.4  114.4  111.3  103.3  114.1  107.0  110.5  104.6  117.8  \n",
       "176  ...  111.7  114.3  114.4  111.4  103.2  114.1  107.0  110.7  104.6  117.7  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "luts['2018_avg_pts_for'].tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we've got ourselves some LUTs! We'll save the dictionary of LUTs so that we can load them into memory later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data/luts2.pkl']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(luts, 'Data/luts2.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
